xgboost可以用来排序.把目标函数改了就行
xgboost可以自定义损失函数, 但是相应的评估函数也要修改. 自定义目标函数需要二次可微. 通过自定义目标函数得到的预测值是模型预测的原始值,不会进行任何转换

import numpy as np


#自定义目标函数logloss,给定预测值，返回一阶，二阶梯度
def logregobj(preds, dtrain):
    labels = dtrain.get_label()
    preds =1.0 / (1.0 + np.exp(-preds))
    grad = preds - labels
    hess = preds * (1.0-preds)
    return grad, hess

#用户自定义评估函数，返回指标名称和结果
def evalerror(preds, dtrain):
    labels = dtrain.get_label()
    #因为是未进行sigmoid转换的，所以以0作为分类阈值
    return 'error', float(sum(labels != (preds > 0.0))) / len(labels)

#通过自定义目标函数进行训练
bst = xgb.train(params, xgb_train, num_round, watchlist, obj=logregobj,feval=evalerror)
