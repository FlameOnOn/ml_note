

关于归一化,看这两篇就够了
https://www.cnblogs.com/shine-lee/p/11779514.html
http://www.bewindoweb.com/216.html
https://blog.csdn.net/zenghaitao0128/article/details/78361038

1. 什么样的模型需要归一化:
涉及或隐含距离计算的算法，比如K-means、KNN、PCA、SVM等，一般需要feature scaling
损失函数中含有正则项时，一般需要feature scaling
梯度下降算法，需要feature scaling
2. 什么样的模型不需要归一化
与距离计算无关的概率模型，不需要feature scaling，比如Naive Bayes；
与距离计算无关的基于树的模型，不需要feature scaling，比如决策树、随机森林等，树中节点的选择只关注当前特征在哪里切分对分类更好，即只在意特征内部的相对大小，而与特征间的相对大小无关

标准化和归一化的区别,为什么归一化会加快收敛速度等问题都看那两篇文章就够了
“将分布转为标准正态分布，均值为0，方差为1”这句话有问题。标准分布的均值为0方差为1，但均值为0方差为1并不一定是正态分布。对数据进行零均值归一化并不会改变数据本身的分布特性。


没归一化的化,等值线的圆会很尖,而梯度是垂直于等值线的.所以会震荡
