如何决定是否使用你所有的数据
如何决定是否添加不一致的数据

这两个问题可以一并回答. 如果增加的数据对我们的学习目标有一定的帮助, 而且我们的模型有学习能力,可以学到即使是分布不一致的数据的一些高维特征,那就是可以增加数据的.
如果没有足够大的神经网络,那么你应该更加关注训练数据，需要与开发集/测试集的分布相匹配。
如果你认为有些数据没有任何帮助，那么应该将这些数据排除在计算原因之外.


添加了分布不一致的数据后,可以给一致的数据那部分样本添加大点的权重. 或者时间序列的话,离现在的越近的样本添加越大的权重.权重就是作用在损失函数上的,权重越大的样本对损失函数的变化贡献越大,所以在学的时候
就会着重让这个差别变小,模型也就会更偏向于学到这部分数据的特性.

xgboost可以用这个方法给每个样本添加权重. sample_weight=curr_sample_weight
self._model.fit(x_train, y_train,sample_weight=curr_sample_weight,
                        verbose=True,
                        early_stopping_rounds=self._params['early_stopping_rounds'],
                        eval_set=self._eval_set,
                        eval_metric=self._params['eval_metric'])


通过对分布不一致的样本(可能是其他途径获取到的样本)赋予更少的权重，你不需要构建一个庞大的神经网络来确保算法在这两种类型的任务上都能很好地完成。只有当你怀疑这些额外的数据（网络图像）与开发/测试集
分布不一致，或者额外的数据规模比与相同分布的开发/测试集（手机图像）数据规模大得多时，这种类型的权重加权才需要

