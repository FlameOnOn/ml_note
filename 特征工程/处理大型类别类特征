处理大型类别变量,one-hot啥的不好使,可以使用压缩特征的方法
压缩特征，有两种方式。
a) 特征散列化，通常用于线性模型。
b) 分箱计数，常用于线性模型和树模型。

散列化很好理解:
分箱计数的思想稍有一点复杂：它不使用分类变量的值作为特征，而是使用目标变量取这
个值的条件概率。换句话说，我们不对分类变量的值进行编码，而是要计算分类变量值与
要预测的目标变量之间的相关统计量。对于那些熟悉朴素贝叶斯分类器的人来说，这个统
计量肯定耳熟能详，因为它就是在所有特征都是独立的这个假设之下的各个类别的条件概
率。

分箱计数假设可以使用历史数据来计算统计量。表 5-6 包含了分类变量的每个可能取值
的累积历史计数。根据用户 Alice 点击广告的次数和她没有点击广告的次数，可以计算
出她点击广告的概率。同样，也可以计算出任意一个查询 - 广告域组合的点击概率。在
训练模型时，只要遇到 Alice，就可以使用她的点击概率作为模型的输入特征。对于像
“0x437a45e1, qux.net”（查询散列值 - 广告域）这样的成对特征，也可以进行同样的处理

还有embbding方法


防止数据泄露
因为分箱计数要依赖历史数据生成必需的统计量，所以它需要等待一段时间以完成数据收
集，这就会在学习流程中导致一点轻微的延迟。还有，当数据分布改变时，需要更新计
数。数据变化得越快，计数重新计算的频率就越高。在像定向广告这样的应用中，用户偏
好和常用查询变化得非常快，所以这个问题变得特别重要，不能适应当前数据分布的变化
意味着广告平台的巨大损失。
有人或许会问：为什么不使用同样的数据集来计算相关统计量和训练模型？这种想法太天
真了。这里最大的问题是，统计量中包含目标变量，而它正是模型试图去预测的。使用输
出去计算输入特征会导致一个非常严重的问题，那就是数据泄露。简单地说，数据泄露会
使模型中包含一些不应该有的信息，这些信息可以使模型获得某种不现实的优势，从而做
出更加精确的预测。出现数据泄露有多种原因，比如测试数据泄露到训练数据中，或者未
来数据泄露到过去数据中。只要模型获得了在生产环境中实时预测时不应该接触到的信
息，就会发生数据泄露。Kaggle 的 wiki 中给出了更多数据泄露的例子，以及它不利于机
器学习应用的原因。
如果在分箱计数过程中使用当前数据点的标签来计算输入统计量，就会造成直接的数据泄
露。防止出现这个问题的一种方法是，严格隔离计数收集（用来计算分箱计数统计量）和
训练，如图 5-5 所示；也就是说，使用过去的数据点进行计数，使用当前的数据点进行训
练（将分类变量映射到我们前面收集到的历史统计量上），再使用未来的数据点进行测试。
这可以解决数据泄露问题，但会引发前面提过的流程延迟问题（输入统计量以及模型会滞
后于当前数据）。
